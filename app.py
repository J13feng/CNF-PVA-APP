import streamlit as st
import joblib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import os
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import datetime
import traceback
import io

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False


# ==========================================
# 1. åŠ è½½èµ„æº (v3.0 å…¨èƒ½ç‰ˆ)
# ==========================================
@st.cache_resource
def load_resources():
    current_dir = os.path.dirname(os.path.abspath(__file__))

    # è·¯å¾„
    models_path = os.path.join(current_dir, 'models_pack.pkl')  # åŠ è½½æ¨¡å‹åŒ…
    scaler_path = os.path.join(current_dir, 'scaler.pkl')
    cols_path = os.path.join(current_dir, 'feature_cols.pkl')
    data_path = os.path.join(current_dir, 'train_data.pkl')

    # åŠ è½½
    models_pack = joblib.load(models_path)
    scaler = joblib.load(scaler_path)
    feature_cols = joblib.load(cols_path)
    train_data = joblib.load(data_path)

    return models_pack, scaler, feature_cols, train_data


try:
    models_pack, scaler, feature_cols, train_data = load_resources()
    # è§£åŒ…æ¨¡å‹
    model_cls = models_pack['svm_cls']
    model_tensile = models_pack['rf_tensile']
    model_elong = models_pack['rf_elong']
    model_trans = models_pack['rf_trans']

    X_train_df = train_data['X_df']
except FileNotFoundError as e:
    st.error(f"âŒ ç¼ºå°‘æ–‡ä»¶: {e}")
    st.info("è¯·å…ˆè¿è¡Œ Train_SVM.py (v3.0) ç”Ÿæˆ models_pack.pkl")
    st.stop()


# ==========================================
# è¾…åŠ©å‡½æ•°ï¼šè¿æ¥ Google Sheets
# ==========================================
def get_gsheet_client():
    scope = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
    current_dir = os.path.dirname(os.path.abspath(__file__))
    json_key_path = os.path.join(current_dir, 'key.json')

    if os.path.exists(json_key_path):
        creds = ServiceAccountCredentials.from_json_keyfile_name(json_key_path, scope)
    elif "gcp_service_account" in st.secrets:
        creds_dict = dict(st.secrets["gcp_service_account"])
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    else:
        return None
    return gspread.authorize(creds)


def add_data_to_gsheet(data_row):
    try:
        cleaned_row = []
        for item in data_row:
            if hasattr(item, "item"): item = item.item()
            cleaned_row.append(item)

        client = get_gsheet_client()
        if not client:
            st.error("æœªæ‰¾åˆ°å¯†é’¥")
            return False

        sheet_id = "1CQ6VoA24v6KNoVOSDoKmM4_1Lv35eC20oxBTJ8opMKw".strip()
        sheet = client.open_by_key(sheet_id).sheet1
        sheet.append_row(cleaned_row)
        return True
    except Exception as e:
        st.error(f"é”™è¯¯: {e}")
        return False


# ==========================================
# ä¾§è¾¹æ ï¼šæ•°æ®ä»ªè¡¨ç›˜ (å›¾æ ‡å·²ä¿®å¤)
# ==========================================
with st.sidebar:
    # ä¿®å¤å›¾æ ‡ï¼šä½¿ç”¨ Emoji æˆ–è€… Streamlit åŸç”Ÿ Logoï¼Œæœ€ç¨³
    st.header("ğŸ§ª å®éªŒå®¤çœ‹æ¿")

    if st.button("ğŸ”„ åˆ·æ–°æ•°æ®"):
        try:
            client = get_gsheet_client()
            if client:
                sheet_id = "1CQ6VoA24v6KNoVOSDoKmM4_1Lv35eC20oxBTJ8opMKw".strip()
                sheet = client.open_by_key(sheet_id).sheet1
                records = sheet.get_all_records()
                df_online = pd.DataFrame(records)

                st.metric("ğŸ“Š ç´¯è®¡æ•°æ®", f"{len(df_online)} æ¡")

                # å°è¯•æ‰¾æœ€å¤§å¼ºåº¦
                # æ¨¡ç³ŠåŒ¹é…è¡¨å¤´
                ts_cols = [c for c in df_online.columns if 'Tensile' in c or 'æ‹‰ä¼¸' in c]
                if ts_cols:
                    max_val = pd.to_numeric(df_online[ts_cols[0]], errors='coerce').max()
                    st.metric("ğŸ† æœ€é«˜å¼ºåº¦è®°å½•", f"{max_val} MPa")
            else:
                st.warning("è¿æ¥å¤±è´¥")
        except:
            st.error("è¿æ¥è¶…æ—¶")

    st.markdown("---")
    st.caption("Developed by FengYan Group")

# ==========================================
# ä¸»é¡µé¢
# ==========================================
st.title("PVA/CNF å¤åˆè–„è†œæ™ºèƒ½åä½œå¹³å° v3.0")

tab1, tab2, tab3 = st.tabs(["ğŸš€ å…¨èƒ½é¢„æµ‹", "ğŸ“ æ•°æ®å½•å…¥", "ğŸ“Š æ·±åº¦åˆ†æ"])

# ==========================================
# Tab 1: é¢„æµ‹ (åˆ†ç±» + 3å›å½’)
# ==========================================
with tab1:
    st.subheader("1. å•ç‚¹å…¨æŒ‡æ ‡é¢„æµ‹")

    col1, col2 = st.columns(2)
    with col1:
        cnf_content = st.number_input("CNF å«é‡ (%)", 0.0, 100.0, 0.5, format="%.3f", key="p_cnf")
        pva_conc = st.number_input("CNF/PVA æµ“åº¦ (%)", 0.0, 100.0, 10.0, key="p_conc")
        num_layer = st.number_input("åˆ®æ¶‚å±‚æ•°", 1, 50, 1, key="p_layer")
        ts_val = st.number_input("å¼ºåº¦ Ts (MPa)", 0.0, 300.0, 25.0, key="p_ts")
    with col2:
        angle1 = st.number_input("è§’åº¦ Angle1", 0.0, 180.0, 0.0, key="p_ang1")
        angle2 = st.number_input("è§’åº¦ Angle2", 0.0, 180.0, 0.0, key="p_ang2")
        thickness = st.number_input("åšåº¦ (mm)", 0.0, 5.0, 0.1, key="p_thick")
        tempo = st.number_input("Tempo å‚æ•°", 0.0, 100.0, 0.0, key="p_tempo")

    craft_option = st.selectbox("å·¥è‰º", ("åˆ®æ¶‚", "æ‹‰ä¼¸", "æ— "), key="p_craft")

    if st.button("ğŸš€ ç«‹å³è®¡ç®—", type="primary"):
        # 1. ç»„è£…
        input_data = {
            'CNF_content': cnf_content, 'CNF/PVA_conc': pva_conc, 'NumofLayer': num_layer,
            'Angle1': angle1, 'Angle2': angle2, 'Thickness': thickness,
            'Ts': ts_val, 'Tempo': tempo,
        }
        input_data[f"Craft_{craft_option}"] = 1
        arr = np.zeros(len(feature_cols))
        for i, col in enumerate(feature_cols): arr[i] = input_data.get(col, 0)

        # 2. é¢„æµ‹
        X_in = scaler.transform(arr.reshape(1, -1))

        # è·‘ 4 ä¸ªæ¨¡å‹
        p_cls = model_cls.predict(X_in)[0]
        p_ten = model_tensile.predict(X_in)[0]
        p_elo = model_elong.predict(X_in)[0]
        p_tra = model_trans.predict(X_in)[0]

        # 3. å±•ç¤º
        st.success("âœ… è®¡ç®—å®Œæˆ")

        # ç¬¬ä¸€è¡Œï¼šéš¾æ˜“åº¦
        res_map = {0: "éš¾ (Hard)", 1: "ä¸­ (Medium)", 2: "æ˜“ (Easy)"}
        color = "red" if p_cls == 0 else "orange" if p_cls == 1 else "green"
        st.markdown(f"**å·¥è‰ºéš¾åº¦:** :{color}[{res_map[p_cls]}]")

        # ç¬¬äºŒè¡Œï¼š3ä¸ªæ€§èƒ½æŒ‡æ ‡
        m1, m2, m3 = st.columns(3)
        m1.metric("é¢„ä¼°å¼ºåº¦ (Tensile)", f"{p_ten:.1f} MPa")
        m2.metric("é¢„ä¼°ä¼¸é•¿ç‡ (Elongation)", f"{p_elo:.1f} %")
        m3.metric("é¢„ä¼°é€å…‰ç‡ (Trans.)", f"{p_tra:.1f} %")

    st.divider()

    # === æ‰¹é‡é¢„æµ‹ ===
    st.subheader("2. æ‰¹é‡é¢„æµ‹ (æ”¯æŒæ‰€æœ‰æŒ‡æ ‡)")
    uploaded_file = st.file_uploader("ä¸Šä¼  Excel æ–‡ä»¶", type=["xlsx"])

    if uploaded_file:
        if st.button("å¼€å§‹æ‰¹é‡è®¡ç®—"):
            try:
                df_upload = pd.read_excel(uploaded_file)

                # é¢„å¤„ç†
                if 'Craft' in df_upload.columns:
                    df_upload = pd.get_dummies(df_upload, columns=['Craft'], prefix='Craft')

                df_input = pd.DataFrame(0, index=df_upload.index, columns=feature_cols)
                for col in feature_cols:
                    if col in df_upload.columns: df_input[col] = df_upload[col]

                X_batch = scaler.transform(df_input.values)

                # æ‰¹é‡é¢„æµ‹æ‰€æœ‰æŒ‡æ ‡
                p_cls = model_cls.predict(X_batch)
                p_ten = model_tensile.predict(X_batch)
                p_elo = model_elong.predict(X_batch)
                p_tra = model_trans.predict(X_batch)

                # å†™å…¥ç»“æœ
                res_map = {0: "éš¾", 1: "ä¸­", 2: "æ˜“"}
                df_upload['é¢„æµ‹_å·¥è‰ºéš¾åº¦'] = [res_map[x] for x in p_cls]
                df_upload['é¢„æµ‹_æ‹‰ä¼¸å¼ºåº¦'] = p_ten
                df_upload['é¢„æµ‹_ä¼¸é•¿ç‡'] = p_elo
                df_upload['é¢„æµ‹_é€å…‰ç‡'] = p_tra

                st.dataframe(df_upload.head())

                # ä¸‹è½½
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    df_upload.to_excel(writer, index=False)
                output.seek(0)
                st.download_button("ğŸ“¥ ä¸‹è½½å®Œæ•´ç»“æœ.xlsx", data=output, file_name="Full_Prediction.xlsx")

            except Exception as e:
                st.error(f"å‡ºé”™: {e}")

# ==========================================
# Tab 2: å½•å…¥ (ä¿æŒä¸å˜)
# ==========================================
with tab2:
    st.header("ğŸ”¬ å®éªŒæ•°æ®åé¦ˆ")
    with st.form("entry_form"):
        c1, c2 = st.columns(2)
        with c1:
            e_cnf = st.number_input("CNF å«é‡ (%)", step=0.01)
            e_conc = st.number_input("CNF/PVA æµ“åº¦ (%)", step=0.1)
            e_layer = st.number_input("åˆ®æ¶‚å±‚æ•°", min_value=1, step=1)
            e_ts = st.number_input("å¼ºåº¦ Ts (MPa)", step=1.0)
        with c2:
            e_ang1 = st.number_input("è§’åº¦ Angle1")
            e_ang2 = st.number_input("è§’åº¦ Angle2")
            e_thick = st.number_input("åšåº¦ (mm)", step=0.01)
            e_tempo = st.number_input("Tempo å‚æ•°")
        e_craft = st.selectbox("æ‰€ç”¨å·¥è‰º", ("åˆ®æ¶‚", "æ‹‰ä¼¸", "æ— "))
        st.divider()
        c3, c4, c5 = st.columns(3)
        with c3:
            e_tensile = st.number_input("æˆå“æ‹‰ä¼¸å¼ºåº¦ (MPa)", step=0.1)
        with c4:
            e_elongation = st.number_input("æ–­è£‚ä¼¸é•¿ç‡ (%)", step=0.1)
        with c5:
            e_transmittance = st.number_input("é€å…‰ç‡ (%)", step=0.1)
        st.divider()
        e_result = st.selectbox("ğŸ§ª ç»¼åˆè¯„ä»· (å¯å»å‘æ€§)", ("éš¾", "ä¸­", "æ˜“"))

        if st.form_submit_button("ğŸš€ æäº¤"):
            ts = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            row = [e_cnf, e_conc, e_layer, e_ang1, e_ang2, e_thick, e_ts, e_tempo, e_craft, e_result, e_tensile,
                   e_elongation, e_transmittance, ts]
            if add_data_to_gsheet(row):
                st.success("âœ… å†™å…¥æˆåŠŸ")

# ==========================================
# Tab 3: æ¨¡å‹åˆ†æ (å‡çº§ç‰ˆï¼šæ”¯æŒå›å½’åˆ†æ)
# ==========================================
with tab3:
    st.header("ğŸ“Š æ¨¡å‹æ·±åº¦åˆ†æ")

    # 1. é€‰æ‹©è¦åˆ†æçš„æ¨¡å‹
    analysis_target = st.selectbox(
        "ğŸ” é€‰æ‹©åˆ†æç›®æ ‡",
        ("å·¥è‰ºéš¾æ˜“åº¦ (åˆ†ç±»)", "æ‹‰ä¼¸å¼ºåº¦ (å›å½’)", "æ–­è£‚ä¼¸é•¿ç‡ (å›å½’)", "é€å…‰ç‡ (å›å½’)")
    )

    # æ ¹æ®é€‰æ‹©ï¼Œç¡®å®šè¦ç”¨çš„æ¨¡å‹
    if "å·¥è‰º" in analysis_target:
        target_model = model_cls
        model_type = "classification"
    elif "æ‹‰ä¼¸" in analysis_target:
        target_model = model_tensile
        model_type = "regression"
    elif "ä¼¸é•¿" in analysis_target:
        target_model = model_elong
        model_type = "regression"
    else:
        target_model = model_trans
        model_type = "regression"

    col_a, col_b = st.columns(2)

    # --- ç›¸å…³æ€§çŸ©é˜µ (é€šç”¨) ---
    # --- ç›¸å…³æ€§çŸ©é˜µ ---
    with col_a:
        st.subheader("ç‰¹å¾ç›¸å…³æ€§")
        if st.checkbox("æ˜¾ç¤ºçƒ­åŠ›å›¾", value=True):
            # å–å‰8åˆ—æ•°å€¼ç‰¹å¾
            numeric_df = X_train_df.iloc[:, :8]

            # 1. è®¡ç®—ç›¸å…³ç³»æ•°
            corr = numeric_df.corr()

            # ==========================================
            # ğŸ› ï¸ ä¿®å¤ç©ºç™½é—®é¢˜ï¼šå°† NaN å¡«å……ä¸º 0
            # ==========================================
            # å¦‚æœæŸåˆ—æ•°æ®å®Œå…¨ä¸€æ ·ï¼ˆæ–¹å·®ä¸º0ï¼‰ï¼Œç›¸å…³æ€§è®¡ç®—ä¼šå¾—åˆ° NaN
            # æˆ‘ä»¬æŠŠå®ƒå¡«ä¸º 0ï¼Œä»£è¡¨â€œæ— ç›¸å…³æ€§â€
            corr = corr.fillna(0)

            # 2. ç”»å›¾
            fig, ax = plt.subplots(figsize=(5, 4))
            sns.heatmap(corr, annot=True, fmt=".2f", cmap='coolwarm', vmin=-1, vmax=1)
            plt.title('é…æ–¹å‚æ•°ç›¸å…³æ€§')

            # 3. æ˜¾ç¤º
            st.pyplot(fig)

            # 4. æ™ºèƒ½æç¤º
            # æ£€æŸ¥ä¸€ä¸‹æ˜¯ä¸æ˜¯çœŸçš„æœ‰æ–¹å·®ä¸º0çš„åˆ—ï¼Œæç¤ºç”¨æˆ·
            # std_dev = numeric_df.std()
            # constant_cols = std_dev[std_dev == 0].index.tolist()
            # if constant_cols:
            #     st.warning(
            #         f"âš ï¸ æ³¨æ„ï¼šä»¥ä¸‹ç‰¹å¾åœ¨æ‰€æœ‰æ•°æ®ä¸­æ•°å€¼å®Œå…¨ç›¸åŒï¼Œå› æ­¤æ— æ³•è®¡ç®—ç›¸å…³æ€§ï¼ˆæ˜¾ç¤ºä¸º0.00ï¼‰ï¼š\n {constant_cols}")

    # --- SHAP åˆ†æ (æ ¹æ®æ¨¡å‹ç±»å‹è‡ªåŠ¨è°ƒæ•´) ---
    with col_b:
        st.subheader("ğŸ§¬ SHAP å…³é”®å› å­åˆ†æ")

        if st.button(f"åˆ†æ: {analysis_target}"):
            X_subset = X_train_df.iloc[:20, :]

            with st.spinner('æ­£åœ¨è®¡ç®—ç‰¹å¾é‡è¦æ€§...'):
                try:
                    plt.clf()

                    if model_type == "classification":
                        # SVM åˆ†ç±»æ¨¡å‹ä½¿ç”¨ KernelExplainer (è¾ƒæ…¢)
                        X_summary = shap.kmeans(X_train_df, 5)


                        def predict_fn(x):
                            if isinstance(x, pd.DataFrame): x = x.values
                            x_scaled = scaler.transform(x)
                            return target_model.predict_proba(x_scaled)


                        explainer = shap.KernelExplainer(predict_fn, X_summary)
                        shap_vals = explainer.shap_values(X_subset)
                        # å– "æ˜“" (Index 2)
                        if isinstance(shap_vals, list):
                            sv = shap_vals[2]
                        else:
                            sv = shap_vals
                        if len(sv.shape) == 3: sv = sv.sum(axis=2)

                    else:
                        # éšæœºæ£®æ—å›å½’æ¨¡å‹ä½¿ç”¨ TreeExplainer (è¶…çº§å¿«ï¼)
                        # æ³¨æ„ï¼šTreeExplainer ä¸éœ€è¦æ ‡å‡†åŒ–åçš„æ•°æ®ï¼Œç›´æ¥ç”¨åŸå§‹æ•°æ®å³å¯(å¦‚æœæ˜¯æ ‘æ¨¡å‹)
                        # ä½†å› ä¸ºæˆ‘ä»¬è®­ç»ƒæ—¶ fit è¿›å»çš„æ˜¯ X_scaledï¼Œæ‰€ä»¥è¿™é‡Œè¿˜æ˜¯ç”¨ X_scaled æ¯”è¾ƒä¸¥è°¨
                        X_subset_scaled = scaler.transform(X_subset.values)
                        explainer = shap.TreeExplainer(target_model)
                        sv = explainer.shap_values(X_subset_scaled)

                    # ç»˜å›¾
                    shap.summary_plot(sv, X_subset, max_display=10, show=False)
                    st.pyplot(plt.gcf(), clear_figure=True)
                    st.success("âœ… åˆ†æå®Œæˆ")

                    if model_type == "regression":
                        st.info("ğŸ’¡ å›å½’æ¨¡å‹è§£è¯»ï¼šçº¢è‰²ç‚¹åœ¨å³è¾¹ = è¯¥ç‰¹å¾æ•°å€¼è¶Šå¤§ï¼Œé¢„æµ‹ç»“æœ(å¦‚å¼ºåº¦)è¶Šé«˜ã€‚")

                except Exception as e:
                    st.error(f"åˆ†æå¤±è´¥: {e}")
                    st.code(traceback.format_exc())